{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d75e89e",
   "metadata": {},
   "source": [
    "<h2>Лабораторная работа №5 по курсу \"Проектирование интеллектуальных систем\"</h2>\n",
    "\n",
    "<p><b>Вариант:</b> 11</p>\n",
    "\n",
    "<p><b>Выполнил:</b> Саврасов П.А. группа ИУ5-24М</p>\n",
    "\n",
    "<h3>Задание</h3>\n",
    "<p>Итоговый код для обучения нейросети и оценки ее точности содержится в приложении.\n",
    "Необходимо увеличить количество скрытых слоев до 3-ех, а количество нейронов в этих слоях так,\n",
    "чтобы обеспечить точность работы нейросети не менее 75%. Темы текстов необходимо изменить в\n",
    "соответствии с вариатом </p>\n",
    "\n",
    "<h4>Задание по варианту:</h4> comp.sys.ibm.pc.hardware, rec.sport.baseball, sci.med, alt.atheism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "61deca3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "37ee4110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text From: sac@asdi.saic.com (Steve A. Conroy x6172)\n",
      "Subject: Re: Darrrrrrrrryl\n",
      "Organization: SAIC\n",
      "Lines: 33\n",
      "\n",
      "In article <mssC5KCru.5Ip@netcom.com>, mss@netcom.com (Mark Singer) writes:\n",
      "|> \n",
      "|> \n",
      "|> The media is beating the incident at Dodger Stadium on Wednesday to\n",
      "|> death, but I haven't seen anything in rsb yet.\n",
      "|> \n",
      "|> Gerald Perry of the Cardinals pinch hit in the eighth inning with two\n",
      "|> on and his club down by a run.  He stroked a line drive into the\n",
      "|> right field corner.  The ball cleared the three-foot high fence and\n",
      "|> went into the crowd.  Darryl, racing over from right center, got to\n",
      "|> the spot in time to reach his glove up over the short fence, but he\n",
      "|> missed the ball.  A fan sitting in the front row, wearing a mitt,\n",
      "|> reached up and caught the ball.  Home run.\n",
      "|> \n",
      "|> Now I've seen the replay several times and I have concluded that\n",
      "|> Darryl missed the ball, and that the fan's glove was essentially\n",
      "|> behind Darryl's.  Several Dodger fans with seats in the immediate\n",
      "|> vicinity have claimed that the fan unquestionably interfered with\n",
      "|> Strawberry.  What cannot be disputed, however, is that the fan\n",
      "|> who caught the ball never took his eye off it;  he was oblivious\n",
      "|> to where the fielder was playing.  He was also quite exuberant as\n",
      "|> soon as he realized he had made the catch.\n",
      "|> \n",
      "|> [Stuff about Daryl and Tommy and everyone blaming fan for the loss deleted]\n",
      "\n",
      "I saw the replay several times too.  No question about it.  Daryl missed\n",
      "the ball, *then* the fan caught it.  Daryl is so tall that he had the\n",
      "first shot at the ball.  Daryl's just whining again.  I think it shows a\n",
      "lack of class when Tommy, Daryl and the Dodgers blame a single fan for\n",
      "losing the game.  What about the pitcher who threw up the gopher ball?\n",
      "What about the pitchers that gave up 6 runs up to that point?  Sorry, Tommy.\n",
      "If it were a 2-1 game and Daryl was 5 feet 2 inches tall, then maybe -\n",
      "just maybe - you'd have an argument.\n",
      "\n",
      "category: 2\n"
     ]
    }
   ],
   "source": [
    "categories = ['comp.sys.ibm.pc.hardware', 'rec.sport.baseball', 'sci.med', 'alt.atheism']\n",
    "ngAll = fetch_20newsgroups(subset='all', categories=categories)\n",
    "print('text', ngAll.data[0])\n",
    "print('category:', ngAll.target[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c6565d",
   "metadata": {},
   "source": [
    "<h4>Параметры обучения</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "af198bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "training_epochs = 10\n",
    "batch_size = 150"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78db65d2",
   "metadata": {},
   "source": [
    "<h4>Параметры нейронной сети</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9fc267b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden_1 = 500 # скрытый слой 1\n",
    "n_hidden_2 = 300  # скрытый слой 2\n",
    "n_hidden_3 = 100  # скрытый слой 3\n",
    "n_classes = len(categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37daeed6",
   "metadata": {},
   "source": [
    "Для подготовки данных воспользуемся функцией векторизации текстов CountVectorizer из библиотеки scikit-learn модуля sklearn.feature_extraction.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6f58dc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "data = vectorizer.fit_transform(ngAll.data).toarray()\n",
    "inputDim = len(vectorizer.get_feature_names())\n",
    "\n",
    "xTrain = data[:2500]\n",
    "yTrain = ngAll.target[:2500]\n",
    "xTest = data[2500:]\n",
    "yTest = ngAll.target[2500:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "93b7c51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "        layers.InputLayer(input_shape=(inputDim)),\n",
    "        layers.Dense(n_hidden_1, activation='relu'),\n",
    "        layers.Dense(n_hidden_2, activation='relu'),\n",
    "        layers.Dense(n_hidden_3, activation='relu'),\n",
    "        layers.Dense(n_classes, activation='relu')\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "615d8932",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile (\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e88b7d0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "17/17 - 2s - loss: 0.8732 - accuracy: 0.6064\n",
      "Epoch 2/10\n",
      "17/17 - 2s - loss: 0.6783 - accuracy: 0.7212\n",
      "Epoch 3/10\n",
      "17/17 - 1s - loss: 0.6695 - accuracy: 0.7232\n",
      "Epoch 4/10\n",
      "17/17 - 2s - loss: 0.6664 - accuracy: 0.7240\n",
      "Epoch 5/10\n",
      "17/17 - 1s - loss: 0.6662 - accuracy: 0.7248\n",
      "Epoch 6/10\n",
      "17/17 - 2s - loss: 0.6651 - accuracy: 0.7240\n",
      "Epoch 7/10\n",
      "17/17 - 2s - loss: 0.6650 - accuracy: 0.7256\n",
      "Epoch 8/10\n",
      "17/17 - 2s - loss: 0.6638 - accuracy: 0.7260\n",
      "Epoch 9/10\n",
      "17/17 - 2s - loss: 0.6642 - accuracy: 0.7260\n",
      "Epoch 10/10\n",
      "17/17 - 1s - loss: 0.6638 - accuracy: 0.7260\n",
      "40/40 - 1s - loss: 0.7055 - accuracy: 0.7233\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7054914832115173, 0.7233201861381531]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(xTrain, yTrain, batch_size=batch_size, epochs=training_epochs, verbose=2)\n",
    "model.evaluate(xTest, yTest, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d190880",
   "metadata": {},
   "source": [
    "<h3>Контрольные вопросы</h3>\n",
    "<ol>\n",
    "    <li>\n",
    "        <h4>Какие вы знаете задачи обработки текстов, в чем они заключаются?</h4>\n",
    "        <ul>\n",
    "            <li>Классификация текстов и предложений</li>\n",
    "            <li>Машинный перевод</li>\n",
    "            <li>Интеллектуальная обработка текстов</li>\n",
    "            <li>Генерация описаний по входному объекту</li>\n",
    "            <li>Автоматическая обработка текстов</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>\n",
    "        <h4>Зачем нужна предобработка текста для машинного обучения?</h4>\n",
    "        <p>Это нужно для использования текстовых данных в нейронных сетях их нужно представить в виде матрицы, каждый элемент будет соответствовать словам.</p>\n",
    "    </li>\n",
    "    <li>\n",
    "        <h4>Какие виды предобработки текста вы знаете?</h4>\n",
    "        <p>Все тексты на естественном языке имеют большое количество слов, которые не несут информации о данном тексте. К примеру, в английском языке такими словами являются артикли, в русском к ним можно отнести предлоги, союзы, частицы. Данные слова называют шумовыми или стоп-словами. Для достижения лучшего качества классификации на первом этапе предобработки текстов обычно необходимо удалять такие слова. Второй этап предобработки текстов — приведение каждого слова к основе, одинаковой для всех его грамматических форм. Это необходимо, так как слова несущие один и тот же смысл могут быть записаны в разной форме. Например, одно и то же слово может встретиться в разных склонениях, иметь различные приставки и окончания.</p>\n",
    "    </li>\n",
    "    <li>\n",
    "        <h4>Что такое стемминг?</h4>\n",
    "        <p>Стемминг — это процесс нахождения основы слова для заданного исходного слова. Основа слова не обязательно совпадает с морфологическим корнем слова. Задача нахождения основы слова представляет собой давнюю проблему в области компьютерных наук. Первая публикация по данному вопросу датируется 1968 годом. Стемминг применяется в поисковых системах для расширения поискового запроса пользователя, является частью процесса нормализации текста.</p>\n",
    "    </li>\n",
    "    <li>\n",
    "        <h4>Что такое 20 Newsgroups?</h4>\n",
    "        <p>20 Newsgroups – это набор, состоящий из примерно 20 тысяч постов.</p>\n",
    "    </li>\n",
    "    <li>\n",
    "        <h4>Чему должно равняться число входных и выходных нейронов в задаче классификации текстов?</h4>\n",
    "        <p>Размер входного слоя должен быть равен количеству уникальных слов в текстах, а размер\n",
    "выходного слоя — количеству классов.</p>\n",
    "    </li>\n",
    "</ol>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
