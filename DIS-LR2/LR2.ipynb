{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "087ab7a5",
   "metadata": {},
   "source": [
    "<h2>Лабораторная работа №2 по курсу \"Проектирование интеллектуальных систем\"</h2>\n",
    "\n",
    "<p><b>Выполнил:</b> Саврасов П.А. группа ИУ5-24М</p>\n",
    "\n",
    "<h3>Задание</h3>\n",
    "    <p>Создать логистическую регрессию для классификации набора данных MNIST.</p>\n",
    "    <p>Создать нейронную сеть с 5 полносвязными слоями для классификации набора данных MNIST с\n",
    "количеством нейронов в слоях от первого до пятого - (200,100,60,30,10).</p>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "550519b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4dc910",
   "metadata": {},
   "source": [
    "Загрузим датасет MNIST и рассмотрим его формат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5a310f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,)\n",
      "(10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "(xTrain, yTrain), (xTest, yTest) = mnist.load_data()\n",
    "\n",
    "print(xTrain.shape, yTrain.shape)\n",
    "print(xTest.shape, yTest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8b2fe5",
   "metadata": {},
   "source": [
    "Как видно, формат датасета (обучающей выборки) следующий: <br>\n",
    "<ul>\n",
    "    <li>60000 образцов изображений</li>\n",
    "    <li>28 пикселей в высоту</li>\n",
    "    <li>28 пикселей в ширину</li>\n",
    "</ul>\n",
    "То есть это трёхмерный массив данных. Такой формат не подходтит для обучения нейросетей, требуется изименить форму датасета на двухмерный массив. Число образцов оставим неизменным, а двумерный массив пикселей преобразуем в одномерный: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f51747dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "xTrain = tf.reshape(xTrain, (60000, 28 * 28))\n",
    "print(xTrain.shape)\n",
    "xTest = tf.reshape(xTest, (10000, 28 * 28))\n",
    "print(xTest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e199ea",
   "metadata": {},
   "source": [
    "Рассмотрим формат одного элемента массива:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5f82729d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<dtype: 'uint8'>\n",
      "tf.Tensor(\n",
      "[  0   0   0  49 238 253 253 253 253 253 253 253 253 251  93  82  82  56\n",
      "  39   0   0   0   0   0   0   0   0   0   0   0   0  18 219 253 253 253\n",
      " 253 253 198 182 247 241   0   0   0   0   0   0   0   0], shape=(50,), dtype=uint8)\n"
     ]
    }
   ],
   "source": [
    "print(xTrain[0].dtype)\n",
    "print(xTrain[0][200:250])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2339771",
   "metadata": {},
   "source": [
    "Формат элемента является 8 битным беззнаковым целым, диапазон значений которого лежит в промежутке от 0 до 255. Такой формат для обучения нейросестей не самый удачный. Произведём масштабирование и преобразуем диапазон от 0 до 1. При этом нужно учесть, что сначала нужно преобразовать тип данных в float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ab005970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<dtype: 'float32'>\n",
      "tf.Tensor(\n",
      "[0.         0.         0.         0.19215687 0.93333334 0.99215686\n",
      " 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686\n",
      " 0.99215686 0.9843137  0.3647059  0.32156864 0.32156864 0.21960784\n",
      " 0.15294118 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.07058824 0.85882354 0.99215686 0.99215686 0.99215686\n",
      " 0.99215686 0.99215686 0.7764706  0.7137255  0.96862745 0.94509804\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.        ], shape=(50,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "xTrain = tf.cast(xTrain, dtype = tf.float32) / 255\n",
    "xTest = tf.cast(xTest, dtype = tf.float32) / 255\n",
    "print(xTrain[0].dtype)\n",
    "print(xTrain[0][200:250])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75bdf91a",
   "metadata": {},
   "source": [
    "Датасет преобразован и готов для обучения моделей <br>\n",
    "Начнём с обучения логистической регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3bec24fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "        layers.InputLayer(input_shape=(28*28)),\n",
    "        layers.Dense(10, activation=tf.nn.log_softmax)\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6598ce6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss = keras.losses.SparseCategoricalCrossentropy(from_logits = True),\n",
    "    optimizer = keras.optimizers.SGD(learning_rate = 0.5),\n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "39ac5bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 - 2s - loss: 0.3758 - accuracy: 0.8908\n",
      "Epoch 2/5\n",
      "1875/1875 - 2s - loss: 0.3210 - accuracy: 0.9094\n",
      "Epoch 3/5\n",
      "1875/1875 - 2s - loss: 0.3092 - accuracy: 0.9127\n",
      "Epoch 4/5\n",
      "1875/1875 - 2s - loss: 0.3012 - accuracy: 0.9155\n",
      "Epoch 5/5\n",
      "1875/1875 - 2s - loss: 0.2972 - accuracy: 0.9174\n",
      "313/313 - 0s - loss: 0.2945 - accuracy: 0.9199\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2944934666156769, 0.9199000000953674]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(xTrain, yTrain, batch_size=32, epochs=5, verbose=2)\n",
    "model.evaluate(xTest, yTest, batch_size=32, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9102ed",
   "metadata": {},
   "source": [
    "Теперь обучим нейронную сеть следующими параметрами:\n",
    "<ul>\n",
    "    <li>Входной слой:   784</li>\n",
    "    <li>Скрытый слой 1: 200</li>\n",
    "    <li>Скрытый слой 2: 100</li>\n",
    "    <li>Скрытый слой 3: 60</li>\n",
    "    <li>Скрытый слой 4: 30</li>\n",
    "    <li>Выходной слой:  10</li>\n",
    "</ul>    \n",
    "Сначала расмотрим упрощённый вариант на основе Sequential API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "70594118",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        layers.InputLayer(input_shape=(28*28)),\n",
    "        layers.Dense(200, activation='relu'),\n",
    "        layers.Dense(100, activation='relu'),\n",
    "        layers.Dense(60, activation='relu'),\n",
    "        layers.Dense(30, activation='relu'),\n",
    "        layers.Dense(10, activation='relu')\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529fef95",
   "metadata": {},
   "source": [
    " Установим модели функцию потерь и оптимизатор (способ минимизации функции потери)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f3f2ea4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss = keras.losses.SparseCategoricalCrossentropy(from_logits = True),\n",
    "    optimizer = keras.optimizers.SGD(learning_rate = 0.5),\n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce67553b",
   "metadata": {},
   "source": [
    "Обучим модель со следующими параметрами:<br>\n",
    "Размер батча (порция данных): 32 образца<br>\n",
    "Число эпох: 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1c8ffd8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 - 4s - loss: 1.3936 - accuracy: 0.5317\n",
      "Epoch 2/5\n",
      "1875/1875 - 4s - loss: 0.7025 - accuracy: 0.7898\n",
      "Epoch 3/5\n",
      "1875/1875 - 4s - loss: 0.1642 - accuracy: 0.9573\n",
      "Epoch 4/5\n",
      "1875/1875 - 4s - loss: 0.1280 - accuracy: 0.9669\n",
      "Epoch 5/5\n",
      "1875/1875 - 4s - loss: 0.1111 - accuracy: 0.9706\n",
      "313/313 - 0s - loss: 0.1453 - accuracy: 0.9667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1453077793121338, 0.96670001745224]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(xTrain, yTrain, batch_size=32, epochs=5, verbose=2)\n",
    "model.evaluate(xTest, yTest, batch_size=32, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc14985f",
   "metadata": {},
   "source": [
    "Теперь повторим тоже самое, но уже с применением Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5c0050c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "inpLayer = keras.Input(shape=(28*28))\n",
    "hidLayer1 = layers.Dense(200, activation='relu')(inpLayer)\n",
    "hidLayer2 = layers.Dense(100, activation='relu')(hidLayer1)\n",
    "hidLayer3 = layers.Dense(60, activation='relu')(hidLayer2)\n",
    "hidLayer4 = layers.Dense(30, activation='relu')(hidLayer3)\n",
    "outLayer = layers.Dense(10, activation='relu')(hidLayer4)\n",
    "\n",
    "model = keras.Model(inputs=inpLayer, outputs=outLayer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d9968e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss = keras.losses.SparseCategoricalCrossentropy(from_logits = True),\n",
    "    optimizer = keras.optimizers.SGD(learning_rate = 0.5),\n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5427b67c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 - 4s - loss: 1.1223 - accuracy: 0.6493\n",
      "Epoch 2/5\n",
      "1875/1875 - 4s - loss: 0.8117 - accuracy: 0.7653\n",
      "Epoch 3/5\n",
      "1875/1875 - 4s - loss: 0.7794 - accuracy: 0.7744\n",
      "Epoch 4/5\n",
      "1875/1875 - 4s - loss: 0.7640 - accuracy: 0.7793\n",
      "Epoch 5/5\n",
      "1875/1875 - 4s - loss: 0.7529 - accuracy: 0.7824\n",
      "313/313 - 0s - loss: 0.7632 - accuracy: 0.7790\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7632175087928772, 0.7789999842643738]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(xTrain, yTrain, batch_size=32, epochs=5, verbose=2)\n",
    "model.evaluate(xTest, yTest, batch_size=32, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f82f379",
   "metadata": {},
   "source": [
    "<h3>Контрольные вопросы</h3>\n",
    "<ol>\n",
    "    <li>\n",
    "        <h4>Что такое Variable?</h4>\n",
    "        <p>\tВ TensorFlow для хранения значений модели существует специальный тип tf.Variable. В отличие от других Tensor объектов которые заново обновляются при каждом запуске сессии, переменные (Variable) хранят фиксированное значение в графе. Это является важным, т.к. при текущее значение переменной влияет на вывод в вычисляемой итерации. Как и другие Tensor объекты, переменные можно использовать как входные значения в графе.</p>\n",
    "    </li>\n",
    "    <li>\n",
    "        <h4>Что такое placeholder?</h4>\n",
    "        <p>\tДля добавления входных данных извне модели в TensorFlow используется специальный тип - плейсхолдер (placeholder). Плейсхолдер можно представить в виде пустой переменной который будет заполняться данными позже. Сперва их используют для создания графа и заполняют данными при выполнении сессии.</p>\n",
    "    </li>\n",
    "    <li>\n",
    "        <h4>Что такое функция потерь?</h4>\n",
    "        <p>Функция потерь(стоимости) – используется в качестве метрики для определения качества модели. Это расстояние(разница) между предсказанием модели и истинным значением входного вектора.</p>\n",
    "    </li>\n",
    "    <li>\n",
    "        <h4>Какие другие названия функции потери?</h4>\n",
    "        <p>Функция стоимости.</p>\n",
    "    </li>\n",
    "    <li>\n",
    "        <h4>Зачем нужна функция потери?</h4>\n",
    "        <p>Функция потерь(стоимости) – используется в качестве метрики для определения качества модели. Это расстояние(разница) между предсказанием модели и истинным значением входного вектора.</p>\n",
    "    </li>\n",
    "    <li>\n",
    "        <h4>Как запустить обучение модели?</h4>\n",
    "        <p><b>Для TensorFlow 1:</b> В метод tf.Session().run() передаем шаг градиентного спуска и значения для placeholder.</p>\n",
    "        <p><b>Для TensorFlow 2:</b> В метод класса keras.Sequential fit передать данные о числе эпох, размеру батча, методу визуализации процесса обучения, и данных для обучения</p>\n",
    "    </li>\n",
    "    <li>\n",
    "        <h4>Что делает tf.global_variables_initializer()?</h4>\n",
    "        <p>Вызывается при вызове метода сессии .run() для создания в оперативной памяти области для хранения переменных и их исходных значений.</p>\n",
    "    </li>\n",
    "    <li>\n",
    "        <h4>Что такое minibatch?</h4>\n",
    "        <p>Небольшая порция примеров из общего датасета. Обычно объем данной подвыборки варьируется от 50 до 500 примеров.</p>\n",
    "    </li>\n",
    "    <li>\n",
    "        <h4>Какие бывают активационные функции?</h4>\n",
    "        <p>Логистическая, тангенсальная и ReLU (Rectified Linear Unit) активационные функции.</p>\n",
    "    </li> \n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb66c4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
